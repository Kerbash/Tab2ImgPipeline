{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:39:33.960171Z",
     "start_time": "2025-06-28T16:39:29.020289Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from libs.find_optimal_size import find_optimal_rectangle\n",
    "\n",
    "from algorithms.gramMatrix.main import GramMatrixPipeline\n",
    "from algorithms.deepinsight.main import DeepInsightPipeline\n",
    "from algorithms.correlationBased.main import CorrelationPixelMappingPipeline\n",
    "from algorithms.igtd.main import IGTDPipeline\n",
    "from algorithms.random.main import RandomStackPipeline\n",
    "from algorithms.refined.main import REFINEDPipeline\n",
    "from algorithms.som.main import SOMFeatureMappingPipeline\n",
    "from algorithms.supertml.main import SuperTMLPipeline\n",
    "\"\"\"\n",
    "All the algorithms assume that all features are numerical and continuous.\n",
    "To use this properly please...\n",
    "1. Make sure there are not NaN values in the dataset.\n",
    "2. Make sure with the exception of the target column, all columns are \"features\" and will be used for training.\n",
    "\n",
    "To use this script please do the following:\n",
    "NOTE! PLEASE MAKE SURE THE DATASET FIRST COLUMN IS THE INDEX AND NOT A FEATURE!\n",
    "[\n",
    "    // Each dictionary is a single dataset\n",
    "    {\n",
    "        \"path\": \"path/to\",\n",
    "        \"filename\": \"filename.csv\",\n",
    "        \"target_column\": \"target_column_name\"\n",
    "    }\n",
    "]\n",
    "\"\"\"\n",
    "DATASETS = [\n",
    "    {\n",
    "        \"path\": \"datasets/sample\",\n",
    "        \"filename\": \"Simple_Classification_Dataset.csv\",\n",
    "        \"target_column\": \"label\",\n",
    "        \"index_col\": 0\n",
    "    }\n",
    "]\n",
    "\n",
    "NORMALIZE_FUNC = MinMaxScaler() # is this how i should store it?\n",
    "\n",
    "\"\"\"\n",
    "For all algorithms please have the following method\n",
    "- fit_transform_save(self, path, x, y)\n",
    "- set_params(self, params) - so that the output and input sizes can be swapped in and out\n",
    "\"\"\"\n",
    "ALGORITHM_CONFIGS = {\n",
    "    \"correlationPixel\": {\n",
    "        \"class\": CorrelationPixelMappingPipeline,\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": False\n",
    "        }\n",
    "    },\n",
    "    \"deepinsight\": {\n",
    "        \"class\": DeepInsightPipeline,\n",
    "        \"default_params\": {\n",
    "            \"feature_extractor\": \"tsne\",\n",
    "            \"discretization\": \"bin\",\n",
    "            \"scaler\": \"standard\",\n",
    "            \"img_format\": \"rgb\",\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": False\n",
    "        }\n",
    "    },\n",
    "    \"gramMatrix\": {\n",
    "        \"class\": GramMatrixPipeline,\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": False\n",
    "        }\n",
    "    },\n",
    "    \"igtd\": {\n",
    "        \"class\": IGTDPipeline,\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": False\n",
    "        }\n",
    "    },\n",
    "    \"random\": {\n",
    "        \"class\": RandomStackPipeline,\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": False\n",
    "        }\n",
    "    },\n",
    "    \"refined\": {\n",
    "        \"class\": REFINEDPipeline,\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": False\n",
    "        }\n",
    "    },\n",
    "    \"som\": {\n",
    "        \"class\": SOMFeatureMappingPipeline,\n",
    "        \"default_params\": {\n",
    "            \"som_shape\": (20, 20),\n",
    "            \"learning_rate\": 0.5,\n",
    "            \"sigma\": 1.0,\n",
    "            \"num_iterations\": 1000,\n",
    "            \"scaler\": \"standard\",\n",
    "            \"neighborhood_function\": \"gaussian\",\n",
    "            \"topology\": \"rectangular\",\n",
    "            \"activation_distance\": \"euclidean\",\n",
    "            \"img_format\": \"rgb\",\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": False\n",
    "        }\n",
    "    },\n",
    "    \"supertml\": {\n",
    "        \"class\": SuperTMLPipeline,\n",
    "        \"default_params\": {\n",
    "            \"random_state\": 42,\n",
    "            \"verbose\": False\n",
    "        }\n",
    "    }\n",
    "}\n"
   ],
   "id": "29745caaef899c4e",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:39:36.085959Z",
     "start_time": "2025-06-28T16:39:33.967192Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# iterate each of the datasets and run each of the algorithms\n",
    "for dataset in tqdm(DATASETS):\n",
    "    # load the dataset\n",
    "    path = os.path.join(dataset[\"path\"], dataset[\"filename\"])\n",
    "    df = pd.read_csv(path, index_col=dataset['index_col'])\n",
    "    X = df.drop(columns=[dataset[\"target_column\"]])\n",
    "    y = df[dataset[\"target_column\"]]\n",
    "\n",
    "    # get the \"rectangle\" with the closest area to the number of features while still being smaller than the number of features\n",
    "    feature_num = X.shape[1]\n",
    "    width, height = find_optimal_rectangle(feature_num)\n",
    "\n",
    "    # for each of the algorithms run the fit_transform_save method\n",
    "    for algorithm in ALGORITHM_CONFIGS.keys():\n",
    "        output_path = os.path.join(dataset[\"path\"], algorithm)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "\n",
    "        # create the algorithm instance\n",
    "        config = ALGORITHM_CONFIGS[algorithm][\"default_params\"].copy()\n",
    "        config[\"output_size\"] = (width, height)\n",
    "        al_instance = ALGORITHM_CONFIGS[algorithm][\"class\"](**config)\n",
    "\n",
    "        print(f\"Running {algorithm} on dataset {dataset['filename']} with output size {config['output_size']}\")\n",
    "        # fit transform and save the results\n",
    "        al_instance.fit_transform_save(output_path, X, y)"
   ],
   "id": "8c6a02465b24ec38",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3265f1d8f60f4da396b92776ad7ca896"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running correlationPixel on dataset Simple_Classification_Dataset.csv with output size (10, 10)\n",
      "Running deepinsight on dataset Simple_Classification_Dataset.csv with output size (10, 10)\n",
      "Running gramMatrix on dataset Simple_Classification_Dataset.csv with output size (10, 10)\n",
      "Running igtd on dataset Simple_Classification_Dataset.csv with output size (10, 10)\n",
      "Running random on dataset Simple_Classification_Dataset.csv with output size (10, 10)\n",
      "Running refined on dataset Simple_Classification_Dataset.csv with output size (10, 10)\n",
      "Running som on dataset Simple_Classification_Dataset.csv with output size (10, 10)\n",
      "Running supertml on dataset Simple_Classification_Dataset.csv with output size (10, 10)\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-28T16:39:36.265280Z",
     "start_time": "2025-06-28T16:39:36.261798Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "eca3d235c2c41211",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
